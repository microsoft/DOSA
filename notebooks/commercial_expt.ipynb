{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprompts\u001b[39;00m \u001b[39mimport\u001b[39;00m PromptTemplate\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommercial\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtemplates\u001b[39;00m \u001b[39mimport\u001b[39;00m SYS_PALM_TEMPLATE, INST_PALM_TEMPLATE\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommercial\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minference_palm\u001b[39;00m \u001b[39mimport\u001b[39;00m palm_completion\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_clues\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from src.commercial.templates import SYS_PALM_TEMPLATE, INST_PALM_TEMPLATE\n",
    "from src.commercial.inference_palm import palm_completion\n",
    "from utils.utils import get_clues\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt_template = PromptTemplate.from_template(SYS_PALM_TEMPLATE)\n",
    "inst_prompt_template = PromptTemplate.from_template(INST_PALM_TEMPLATE)\n",
    "df = pd.read_csv('/home/t-sahuja/cultural_artifacts/clues/punjab/punjab_clues.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clues = df['clues'].iloc[0].strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = sys_prompt_template.format(cluelist=output)\n",
    "inst_prompt = inst_prompt_template.format(state='Punjab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n   Name the object on the basis of the above clues from Punjab. After your guess, I will let you know if you are correct or not. If you're correct, do not make any further guesses and end the conversation. If you are wrong, make your second and final guess. I do not need to know your reasoning behind the answer. Just tell me the answer and nothing else. If you do not know the answer, say that you do not know the answer. Format your answer in the form of ANSWER: your_answer_here.\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "palm_resp = palm_completion(sys_prompt = sys_prompt, inst_prompt=inst_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ANSWER: Lassi\\n\\nIs this correct?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palm_resp.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am glad that I was able to guess the correct answer. Lassi is a popular Punjabi drink made from curd. It is a refreshing and healthy drink that is often served during the summer. It is also a good source of protein and calcium.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palm_resp.reply('yes, this is correct').last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(columns=['guess1', 'guess2', 'ground_truth', 'clues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outputs(df, df_eval):\n",
    "    for i, row in df.iterrows():\n",
    "        print(f\"artifact--{i}---\")\n",
    "        clues = row[\"clues\"].strip().split(\"\\n\")\n",
    "        artifact = row[\"artifact\"].lower().strip()\n",
    "        output = \"\"\n",
    "        for j, clue in enumerate(clues):\n",
    "            output += f\"CLUE-{j+1}: {clue}\\n\"\n",
    "            fin_clues = output.strip()\n",
    "        \n",
    "        palm_resp = palm_completion(sys_prompt=sys_prompt, inst_prompt=inst_prompt)\n",
    "        palm_reply = palm_resp.last\n",
    "        guess1 = palm_reply.split('\\n')[0].split(':')[1].lower()\n",
    "        if artifact in guess1:\n",
    "            df_eval = df_eval.append(\n",
    "                {\n",
    "                    \"guess1\": guess1,\n",
    "                    \"guess2\": \"NA\",\n",
    "                    \"ground_truth\": artifact,\n",
    "                    \"clues\": row[\"clues\"],\n",
    "                },\n",
    "                ignore_index=True,\n",
    "            )\n",
    "            continue\n",
    "        else:\n",
    "            palm_2nd_resp = palm_resp.reply('your guess was not correct')\n",
    "            palm_2nd_reply = palm_2nd_reply.last\n",
    "            guess2 = palm_2nd_reply.split('\\n')[0].split(':')[1].lower()\n",
    "            if artifact in guess2:\n",
    "                df_eval = df_eval.append(\n",
    "                {\n",
    "                    \"guess1\": guess1,\n",
    "                    \"guess2\": guess2,\n",
    "                    \"ground_truth\": artifact,\n",
    "                    \"clues\": row[\"clues\"],\n",
    "                },\n",
    "                ignore_index=True,\n",
    "            )\n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "culture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
