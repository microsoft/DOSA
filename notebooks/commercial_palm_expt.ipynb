{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from src.commercial.templates import SYS_PALM_TEMPLATE, INST_PALM_TEMPLATE\n",
    "from src.commercial.inference_palm import palm_completion\n",
    "from utils import get_clues\n",
    "import os\n",
    "import pandas as pd\n",
    "from const import STATE_CLUES_NOTES_DICT\n",
    "from typing import Dict, List\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys_prompt_template = PromptTemplate.from_template(SYS_PALM_TEMPLATE)\n",
    "inst_prompt_template = PromptTemplate.from_template(INST_PALM_TEMPLATE)\n",
    "df = pd.read_csv(\"/home/t-sahuja/cultural_artifacts/clues/tamil_nadu/tamil_clues.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clues = df[\"clues\"].iloc[9].strip().split(\"\\n\")\n",
    "output = \"\"\n",
    "for j, clue in enumerate(clues):\n",
    "    output += f\"CLUE-{j+1}: {clue}\\n\"\n",
    "fin_clues = output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = sys_prompt_template.format(cluelist=fin_clues)\n",
    "inst_prompt = inst_prompt_template.format(state=\"Tamil Nadu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palm_resp = palm_completion(\n",
    "    sys_prompt=sys_prompt.strip(), inst_prompt=inst_prompt.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palm_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palm_resp.reply(\"yes, this is correct\").last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(columns=[\"guess1\", \"guess2\", \"ground_truth\", \"clues\"])\n",
    "inst_prompt = inst_prompt_template.format(state=\"Punjab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outputs(df, sys_prompt_template, inst_prompt):\n",
    "    df_eval = pd.DataFrame(columns=[\"guess1\", \"guess2\", \"ground_truth\", \"clues\"])\n",
    "    for i, row in df.iterrows():\n",
    "        print(f\"artifact--{i}---\")\n",
    "        clues = row[\"clues\"].strip().split(\"\\n\")\n",
    "        artifact = row[\"artifact\"].lower().strip()\n",
    "        output = \"\"\n",
    "        for j, clue in enumerate(clues):\n",
    "            output += f\"CLUE-{j+1}: {clue}\\n\"\n",
    "            fin_clues = output.strip()\n",
    "\n",
    "        sys_prompt = sys_prompt_template.format(cluelist=output)\n",
    "        palm_resp = palm_completion(sys_prompt=sys_prompt, inst_prompt=inst_prompt)\n",
    "        palm_reply = (\n",
    "            palm_resp.last\n",
    "            if palm_resp != \"Answer: api failed\"\n",
    "            else \"Answer: api failed\"\n",
    "        )\n",
    "        guess1 = palm_reply.split(\"\\n\")[0].split(\":\")[1].lower().strip()\n",
    "        if artifact in guess1 or \"api failed\" in guess1:\n",
    "            df_eval = df_eval.append(\n",
    "                {\n",
    "                    \"guess1\": guess1,\n",
    "                    \"guess2\": \"NA\",\n",
    "                    \"ground_truth\": artifact,\n",
    "                    \"clues\": \"\\n\".join(clues),\n",
    "                },\n",
    "                ignore_index=True,\n",
    "            )\n",
    "            continue\n",
    "        else:\n",
    "            palm_2nd_resp = palm_resp.reply(\n",
    "                \"Your first guess is not correct. While making your second guess, please stick to the format as ANSWER: your_answer_here\"\n",
    "            )\n",
    "            palm_2nd_reply = palm_2nd_resp.last\n",
    "            guess2 = palm_2nd_reply.split(\"\\n\")[0].split(\":\")[1].lower()\n",
    "            df_eval = df_eval.append(\n",
    "                {\n",
    "                    \"guess1\": guess1,\n",
    "                    \"guess2\": guess2,\n",
    "                    \"ground_truth\": artifact,\n",
    "                    \"clues\": \"\\n\".join(clues),\n",
    "                },\n",
    "                ignore_index=True,\n",
    "            )\n",
    "\n",
    "    return df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compile_results(\n",
    "    STATE_CLUES_NOTES_DICT: Dict[str, List[str]],\n",
    "    output_dir: str,\n",
    "    inst_prompt: PromptTemplate,\n",
    "    sys_prompt: str,\n",
    "):\n",
    "    for state_name, val in STATE_CLUES_NOTES_DICT.items():\n",
    "        inst_template = inst_prompt.format(state=state_name)\n",
    "        curr_path = os.path.join(output_dir, state_name)\n",
    "        if not os.path.exists(curr_path):\n",
    "            os.makedirs(curr_path)\n",
    "        clue_path = val[0]\n",
    "        notes_path = val[1] if len(val) > 1 else None\n",
    "\n",
    "        #         print(\"Getting results for {key}ate\")\n",
    "        print(f\"getting results for {state_name} state\")\n",
    "        #         conversation_buffer.clear()\n",
    "        df_clues = pd.read_csv(clue_path)\n",
    "\n",
    "        print(f\"Running clues eval for {state_name} state\")\n",
    "        clues_result_path = os.path.join(curr_path, \"eval_original_artifacts.csv\")\n",
    "        if not os.path.exists(clues_result_path):\n",
    "            df_clues_eval = get_outputs(df_clues, sys_prompt, inst_template)\n",
    "            df_clues_eval.to_csv(clues_result_path, index=False)\n",
    "        else:\n",
    "            print(f\"Clue eval results already exist for {state_name} state\")\n",
    "\n",
    "        if notes_path:\n",
    "            #             conversation_buffer.clear()\n",
    "            df_notes = pd.read_csv(notes_path)\n",
    "            notes_result_path = os.path.join(curr_path, \"eval_expanded_artifacts.csv\")\n",
    "            if not os.path.exists(notes_result_path):\n",
    "                print(f\"Running notes eval for {state_name} state\")\n",
    "                df_notes_eval = get_outputs(df_notes, sys_prompt, inst_template)\n",
    "                df_notes_eval.to_csv(notes_result_path, index=False)\n",
    "            else:\n",
    "                print(f\"Notes eval results already exist for {state_name} state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_template = PromptTemplate(input_variables=[\"state\"], template=INST_PALM_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_results(\n",
    "    STATE_CLUES_NOTES_DICT=STATE_CLUES_NOTES_DICT,\n",
    "    output_dir=\"/home/t-sahuja/cultural_artifacts/results/commercial/palm\",\n",
    "    inst_prompt=inst_template,\n",
    "    sys_prompt=SYS_PALM_TEMPLATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:culture]",
   "language": "python",
   "name": "conda-env-culture-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
